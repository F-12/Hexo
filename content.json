{"pages":[{"title":"about","text":"","link":"/Hexo/about/index.html"}],"posts":[{"title":"2019-05-13 项目小结","text":"本文记录2018-08 ～ 2019-06 后端开发项目总结。项目列表EunomiaOSB监控平台Eunomia微服务编排中间件。技术选型RabbitMQ用来做可靠消息队列MongoDB存储workflow定义Redis缓存，需要加锁的地方使用Redis做分布式锁开发职责根据 solution architecture 的要求给出技术方案领域模型设计消息通信模型设计类图设计、时序图执行引擎模块代码开发存储层模块代码开发功能介绍流程建模流程定义存储流程实例化流程执行结果返回流程建模前端h5应用，画图保存为json格式。json中定义 start、end、sequence、task 四种类型对象。流程定义存储使用mongo存储，一个流程存储为flow collection里的document。每个流程定义存在唯一id表示flow的定义id。流程实例化有应用层服务接口触发。接口发出的 trigger event header 中携带 flow definition id。Eunomia 根据flow definition id 查找到流程进行实例化。流程查找redis里存在一个hash，key为flow definition id，value为flow的active状态。1为可用，0为失效。空为未缓存。flow defintion的json对象存储在flow_definition_namespace:查询的流程为有效缓存用缓存，没有缓存从mongodb中加载并更新到缓存。流程更新先写mongodb写成功后，将缓存中的流程写为失效更新缓存里的json对象更改redis里存储flow active hash里对应flow id的active状态流程执行串行节点：接到一个event取出 header里的task id， 根据 sequence 找到下一个节点发送执行的command并行节点：接到一个event取出 task id，根据 sequece 找到多个节点，并行执行合并节点：并行执行的路径在合并节点处等待每个并行路径执行结束如何处理并行节点并行比较简单，只需要将上一步数据copy一份对每个节点发送对应的command多实例时如何处理合并节点处理合并节点需要考虑如下问题：如何判断继续下一步执行多节点情况下，如何确保流程不会中断多节点情况下，如何确保流程不会重复执行redis中对每个flow instance定义了一个hash，hash 的 key 为 task id，value 为 task 执行结果。执行合并节点逻辑：检查当前合并节点是否已经在执行，若正在执行，什么也不做若没有执行，检查合并节点的所有前置节点的执行结果是否存在若没有全部存在，则没50ms后重新检测若全部存在，设置当前合并节点为正在执行设置成功，则找到合并节点下一节点，继续执行设置失败，则什么也不做问题1: 先检查是否在执行，是为了防止重复执行后续流程，确保经过合并后只有一个执行路径问题2: 检查所有前置节点结果，是为了决定当前分支流程是否全部执行结束问题3: 睡50ms后重新检测是为了防止并发导致每个节点都放弃执行流程导致流程中断执行问题4: 设置当前合并节点为正在执行，利用redis的 setnx 操作，保证只有一个节点设置成功，其他设置失败，确保合并后也只有一个执行路径结果返回client侧会监听的replay channel的消息。reply channel 使用了 rabbitmq fanout exchange，实现对同一个服务不同实例的事件广播。服务实例接受到 reply 消息，会根据message 里的 trasactionId找到一个AysncTask对象进行唤醒（notify）。唤醒后，回复响应给请求端。性能指标5 ms/事件亮点支持两种请求模式异步模式和同步模式。异步模式在请求进来后，生成唯一transaction id，请求存储后，后续流程可以异步继续执行。同步模式在请求进来后，生成transaction id，请求存储后，会提交一个AsyncTask，然后wait，等待被唤醒。设置超时时间60s。超时则返回超时错误码和transaction id。支持CQRS流程定义时可以对查询服务发送command，通过command message携带数据给query service。query service将数据转换为自己的结构存储，支持后续查询服务。支持事务型应用和查询类服务分离。支持前端接口类应用和后台业务类服务隔离。支持saga实现了saga，分布式事务每个流程开始时，生成全局事务id。每个task command中包含局部事务id。根据task执行结果决定是否回滚事务。回滚按照存储的command的逆序时间发送对应command的abort command。对于外部服务，通过调用与之对应的取消操作。支持横向扩展流程状态类数据均写入redis，Eunomia本身只进行计算。因而执行性能比较好。1G CPU 1G内存的情况下，单个节点支持80无压力平均长度为6的流程，100% CPU 平均每个 trasaction 耗时 200ms多每个 message 处理时间大约 10ms。OSB项目介绍车联网项目。三种类型终端：车载终端、车主app、车内控制器功能包括：在线服务预约：保养预约、洗车服务、修车服务、零件购买、代驾服务车控检测：车辆健康监控及提醒，比如空调状态，车灯状况业务及系统指标600w 汽车请求量高峰期，3000/min压测，1G CPU，1G内存，单节点，可支持50并发，支持横向扩展技术选型部署在pcf PasS平台spring cloudRabbitMQ做消息队列RedisAzure SQL Server开发职责领域模型设计骨架代码开发分拆开发任务，指导其他三个成员，进度管控review代码项目亮点OSB关于领域驱动设计方法论的实践数据迁移方案DDD：核心在于统一概念，建立深层领域模型战术层面的模式：Aggregate root、Entity、Value、Repository、Factory、Service战略层面的模式：限界上下文、Context Map、大型结构技术储备Redis分布式锁RedLockRedisson5种数据结构网络多路复用模型RabbitMQAMQP协议四种Exchange与 Kafka对比","link":"/Hexo/2019/05/13/2019-05-13-项目小结/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new \"My New Post\"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment","link":"/Hexo/2019/04/20/hello-world/"},{"title":"微服务监控告警——使用SpringBootAdmin对服务进行实时可视化管理","text":"Spring Boot Admin 介绍Spring Boot Admin 是基于 Spring Actuator组件提供的 REST API的一个管理后台应用。我们将使用Spring Boot Admin下面的几项功能，构建我们部分可视化微服务管理能力。服务健康监控我们一般需要一个可视化方式实时感知当前有多个微服务部署，每个服务当前是否健康，每个服务同时运行多少个节点等。Spring Boot Admin关于服务状态的可视化dashboard可以帮我们做到这一点。元数据管理维护人信息随着应用规模的增长，微服务数目势必会持续增加。我们会希望知道某服务是由谁维护，以便于出现问题时能够快速知道该联系谁来解决。当一个服务有多个维护者时，我们也希望能够知道当前运行的服务版本是由谁部署的。类似需求可以使用Spring Boot Actuator的 /info endpoint机制完成。每个微服务在其应用配置文件的 info 节点下可以维护类似如下结构：1234567891011info: maintainer: - name: F-12 email: fwang98@ford.com phone: 123456789100 - name: Tommy email: MLUO@ford.com phone: 123456789101 owner: name: F-12 email: fwang98@ford.comSpring Boot Admin 会自动生成一个 info panel:进程运行时监控实时资源数据对于java应用，我们需要了解当前jvm运行状况的数据。Spring Boot Actuator /metrics节点提供了这些信息， Spring Boot Admin默认提供了一分钟信息的实时可视化能力。ThreadDump信息Spring Boot Admin提供的 Thread Dump Panel可以看到当前活跃和不活跃的线程具体信息。HeapDump能力同时Spring Boot Admin提供Heap Dump功能，可以方便得下载heap dump文件到本地，然后使用诸如jconsole等工具分析类似OOM或着性能问题。配置管理Spring Boot 应用经常存在大量配置信息。 Spring Cloud默认使用Config Server的组件进行管理。可是Config Server默认基于git的管理方式，对于大量服务配置的管理工作带来一定麻烦。Spring Boot Admin提供了配置信息展示能力。同时提供了一个简易的Environment Manager功能用来修改配置。Logger管理Spring Boot Admin提供动态修改应用内logger level的能力。应用一般设置的info级别的logger，在临时需要观察更丰富logging时比较有用。","link":"/Hexo/2019/04/23/微服务监控告警——SpringBootAdmin/"},{"title":"微服务监控告警——使用Grafana Webhook通知Webex Teams","text":"背景Grafana支持Alert，但是Notification Channel不支持Webex TeamsAlert方案使用Grafana Webhook实现一个Adapter，接受Grafana通知Apdater接受通知，再发送Webex Teams通知Alert反馈方案在Webex Teams里回复消息，指定回复模式触发Webex Teams HookWebex Teams Adpater负责将消息翻译为对特定alert的暂停、重置等功能Adpater可以提供Alert管理功能，比如记录谁处理哪个时间的哪个alert，以及处理结果，和root cause分析","link":"/Hexo/2019/04/26/微服务监控告警——使用Grafana-Webhook通知Webex-Teams/"},{"title":"微服务监控告警——使用Prometheus监控PCF Provided RabbitMQ","text":"背景Cloud Foundry中的RabbitMQ是以Service的形式提供，我们需要监控关于RabbitMQ运行状况的一些指标。监控系统选择使用Prometheus作为存储引擎，但是Prometheus无法直接访问部署在云环境上的PCF里的RabbitMQ。方案在PCF上创建RabbitMQ的service-key，提供一个可以访问RabbitMQ HTTP API的账号1cf create-service-key My-RabbitMQ-Service rabbitmq_exporter使用如下命令获取RabbitMQ各个节点的元数据1cf service-key My-RabbitMQ-Service rabbitmq_exporter数据如下形式：123456789101112131415161718192021222324252627282930313233343536{ \"dashboard_url\": \"https://rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/#/login/HOSTNAME/PASSWORD\", \"hostname\": \"10.227.200.200\", \"hostnames\": [ \"10.227.200.200\" ], \"http_api_uri\": \"https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/\", \"http_api_uris\": [ \"https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/\" ], \"password\": \"PASSWORD\", \"protocols\": { \"amqp\": { \"host\": \"10.227.200.200\", \"hosts\": [ \"10.227.200.200\" ], \"password\": \"PASSWORD\", \"port\": 5672, \"ssl\": false, \"uri\": \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\", \"uris\": [ \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" ], \"username\": \"HOSTNAME\", \"vhost\": \"d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" } }, \"ssl\": false, \"uri\": \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\", \"uris\": [ \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" ], \"username\": \"HOSTNAME\", \"vhost\": \"d9a9c1ab-2383-400b-b5e8-3b84dabe221a\"}在Host 192.168.8.101上对每一个RabbitMQ节点部署一个rabbitmq_exporter应用，提供prometheus访问的metrics endpoint1RABBIT_URL=https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com RABBIT_USER=HOSTNAME RABBIT_PASSWORD=PASSWORD PUBLISH_PORT=9419 ./rabbitmq_exporter在Prometheus Server的配置中增加rabbitmq_exporter的抓取配置123456scrape_configs: - job_name: &apos;rabbitmq_exporter&apos; metrics_path: &apos;/metrics&apos; scrape_interval: 15s static_configs: - targets: [&apos;192.168.8.101:9419&apos;]监控指标结合RabbitMQ自身Metrics，制定如下监控项：存活状态存活节点数Exchange总数Queues总数连接数每个queue中待处理的Message数目每个queue中处理中的message数目RabbitMQ Server的内存使用情况每个Exchange中的rabbitmq_exchange_messages_published_in_total变化趋势每个Exchange中的rabbitmq_exchange_messages_published_out_total变化趋势特定Exchange中每个queue的rabbitmq_queue_consumers数目变化趋势特定Exchange中每个queue的rabbitmq_queue_disk_reads_total数目变化趋势特定Exchange中每个queue的rabbitmq_queue_disk_writes_total数目变化趋势特定Exchange中每个queue分配的内存数目特定Exchange中每个queue中message占用的内存数目更多指标可以参见rabbitmq_exporter的metrics列表。","link":"/Hexo/2019/04/25/微服务监控告警——使用Prometheus监控PCF-Provided-RabbitMQ/"},{"title":"微服务监控告警——使用Prometheus构建监控Dashboard","text":"Metrics与可视化当谈及微服务监控时，实际上，监控的对象并不是微服务，而是微服务的metrics，即指标。对于Metrics的监控，分为两个阶段：Metrics收集阶段Metrics可视化阶段","link":"/Hexo/2019/04/23/微服务监控告警——使用Prometheus构建监控Dashboard/"},{"title":"微服务监控告警——功能篇","text":"背景目前我们的项目采用了基于Spring Cloud的微服务架构。微服务数目随着业务功能的扩展持续增加。我们需要监控各个微服务在生产环境的运行状况，在出现异常时收到报警，以便及时跟进处理。项目的基本情况如下：部署在Pivotal Cloud Foundry平台使用的PCF提供的基于Eureka的服务注册中心使用PCF提供的Redis服务实例使用PCF提供的RabbitMQ服务实例使用部署在Azure上的SQL Server使用部署在Azure上的MongoDB包含十几个自主开发的微服务生产环境的服务输出的log会统一收集到splunk中项目成员使用Webex Teams作为沟通工具目标构建一个监控告警系统确定监控内容确定告警策略方案监控部分健康监控生产环境可能存在多个不同服务，每个服务可能存在多个节点。我们的项目使用了Eureka作为服务注册中心，Eureak本身会包含已注册微服务的心跳数据。对于这种现状，我们的监控系统需要能够做到：告诉我们哪些服务正在运行，哪些服务已经宕机。告诉我们每个服务各自有多少节点告诉我们每个服务的多个节点里有几个正在运行、有几个已经宕机。最好可以和Eureka集成或使用Eureka中的注册信息。以上信息必须可以通过可视化大盘展示环境监控生产环境的微服务可能运行在Host中、VM中或者云平台的容器中。微服务会依赖宿主运行环境中的CPU资源、内存资源、磁盘资源。我们的微服务运行在PCF平台的容器中，这些资源在服务启动时指定，目前没有使用弹性资源策略。当微服务在生产环境运行时，对这些资源的动态信息，我们的监控系统需要能够做到：展示最大CPU资源数及当前CPU占用率展示最大内存资源数及当前内存已使用量展示最大磁盘资源数及当前磁盘已使用量除了宿主环境的资源信息，我们的微服务都使用java开发，针对jvm的情况，我们的监控系统还需要做到：展示jvm的堆内存最大量及已使用量展示jvm的栈内存最大量及已使用量展示jvm内线程活跃数、空闲数、总线程数等信息展示jvm gc次数，full gc次数，gc耗时等信息RabbitMQ监控项目中使用了RabbitMQ，针对RabbitMQ，我们的监控系统需要能够做到：展示当前已存在的Exchange总数展示当前已存在的Queue总数展示当前建立到RabbitMQ的连接数展示每个queue当前排队待处理的message数目展示每个Exchange上绑定的queue的数目展示每个queue上的consumers数目展示每个queue占用的内存大小Redis监控项目中使用了Redis。针对Redis，我们的监控系统需要能够做到：展示Redis的客户端数目每秒执行的Command数目每秒接受的Command数目总内存大小已使用内存大小随时间的变化网络吞吐量每个节点存储的key的数目资源监控SQL ServerSQL Server需要监控的内容如下：DTU Max，Used，PercentageSuccessful Connections Percentage连接数max，usage，percentageTBDMongoDBMongoDB监控内容：Disk Max，Usage连接数Max，UsageTBD性能监控性能监控能力主要包括两部分：自身服务接口响应性能和外部服务调用的响应性能。针对服务响应性能需要收集一下指标：平均每秒请求数平均接口响应时间TP90接口响应时间TP95接口响应时间TP99接口响应时间告警部分监控指标报警当监控系统能够监控到各个微服务健康状态，运行环境的资源状态已经特定中间件的运行状态等不同指标信息后，我们的监控系统需要能够为每个指标指定一个告警策略。比如当宿主环境CPU占用率在最近的5分钟持续高于90%比如过去2小时full gc发生次数大于10比如redis已使用内存占用率超出80%业务异常告警服务运行时不可避免会出现业务异常。通常我们会使用log来输出异常信息。我们的项目使用splunk收集服务的log信息，因而我们系统需要能够利用利用splunk的搜索功能，在log信息中出现exception信息时，通过webex teams通知到服务负责人。告警处理流程我们希望的开发处理告警的流程为：Alert Channel收到AlertAlert类型包括Exception Alert、Metrics AlertException Alert内容包含Alert Id，Exception描述信息，Exception来自哪个服务，Exception来自哪个环境（Stage、Prod），Splunk Exception Log链接Metrics Alert内容包括Alert Id，Alert Rule Id， Alert Rule Name，Alert Rule Message，Alert Metrics当前具体值开发开始处理alert时，在Channel中发送： @AlertBot processing #Alert静默半小时开发处理完Alert后，在Channel中发送： @AlertBot finished #重新打开该类型的alert","link":"/Hexo/2019/04/28/微服务监控告警——功能篇/"},{"title":"砖瓦集——DDD基本构造块实践","text":"本文记录领域驱动设计实践过程中关于基本构造块的最佳实践。概述领域驱动设计（DDD）作为一个OO设计方法论，不应该是只停留在纸面上的概念。DDD应该是指导性的，可实践的。DDD包含很多战术层面的基本模式，如下图：本文用来记录在DDD实践过程对于这些基本构造块的实践心得。背景lombok：不写没有意义的代码，人生苦短，节约生命jackson： spring默认集成的json序列化框架jpa： 成熟的ORM框架本文最佳实践均基于上述描述的工具阐述。Value ObjectValue Object 的实现：12345678910@Value@Builder@JsonDeserialize(builder = ValueObject.Builder.class)public class ValueObject { String property1; String property2; /** 用来进行逻辑计算的方法 */ public String methodA() { return \"SOME_STRING\";}}上述示例完成了如下考虑点：@Value将ValueObject封装为 immutable 类型，因而可以安全在多线程环境下共享@Builder 提供了模版化的生成器模式@JsonDeserialize 指定了jackson反序列化的创建方式但是和JPA交互时存在问题，缺少无餐构造函数。","link":"/Hexo/2019/05/13/砖瓦集——DDD基本构造块实践/"},{"title":"砖瓦集——Java Fork/Join","text":"本文是关于 Fork／Join 框架的学习笔记。目标系统了解Java的Fork/Join框架，已经以下元素的概念和用法。ForkJoinTaskForkJoinPool","link":"/Hexo/2019/05/11/砖瓦集——Java-Fork-Join/"},{"title":"砖瓦集——Java Lock","text":"本文是关于 Lock 框架的学习笔记。目标Lock和ReadWriteLock显示锁和监视器锁ReentrantLockReentrantReadWriteLock背景知识操作系统层面锁的特性java对象锁java中实现了对象锁，又叫监视器锁。每个对象占据的内存开始有段区域叫 Mark Word。Mark Word 里存在一些位来管理当前持有此对象锁的线程信息。Mark Word由jvm管理。java一开始提供了 synchronized 和 volatile 关键字来支持线程同步。synchronizedsynchronized和对象锁的交互：synchronized修饰的static方法使用类的Class对象的对象锁synchronized修饰的非static方法使用当前类实例对象的对象锁synchronized块使用指定的对象的对象锁synchronized使用注意点：synchronized关键字不能继承，子类覆盖方法需要重新声明接口方法时不能使用synchronized关键字构造方法不能声明synchronized关键字，内部可以使用synchronized代码块但不推荐synchronized实现了java中的锁的语义：互斥性可见性原子性volatilevolatile的功能和Java Memory Model的实现有关。JMM示意图如下：volatile保证保证共享变量可见性volatile保证了其修饰的共享变量在线程间的可见性。JMM保证了线程不会读到过期的共享变量。volatile禁止指令重排编译器和处理器优化的原则是：对于单线程程序和正确同步的多线程程序，只要不改变程序的执行结果，编译器和处理器可以随意优化。优化过程中的指令重排很常见。123456789101112// 共享变量int a;boolean b;// 线程1a = 42;b = false// 线程2if(b) { System.out.println(\"do something\");}System.out.println(\"a=\"+a);未指令重排的情况下，因为线程1里对于a和b的初始化不存在依赖，优化后的指令执行顺序可能时先写b，再写a。会导致线程2执行结果不确定，引发线程安全问题。导致这种情况的本质原因是多个线程对不同共享变量的访问有顺序依赖，但jvm优化时指令重排会破坏这种顺序，引发线程安全问题。解决方法是对这种共享变量用volatile修饰以禁止指令重排。volatile不保证原子性上面例子通过给a和b加上volatile修饰，可以解决指令重排导致的线程安全问题，但是不能保证a和b的初始化是原子操作，依然存在线程安全问题。happens-before原则happens-before原则是JMM在优化过程中和程序员直接的协议。具体有8条：程序顺序规则监视器锁规则volatile变量规则传递性start规则join规则中断规则finalize规则locklock包是java提供的的显式锁的抽象。设计的关切点是实现灵活的锁操作。synchronized难用隐式锁链式锁实现难： 申请和释放是按照严格词法作用域进行，需要精心组织代码块只支持互斥锁语义，不支持共享锁及其他锁语义锁语义策略implicit monitor lockguaranteed orderingnon-reentrantdeadlock detection加锁方式三种加锁的形式：可中断式（interruptible）不可中断式（non-interruptible）限时式（timed）根据申请时是否阻塞分为：阻塞式加锁（lock方法）非阻塞式加锁（tryLock方法）锁的类型按加锁目的分为：读锁写锁按分配锁的方式分为：公平锁：直接排队获取，实现FIFO方式加锁非公平锁：先尝试获取锁，获取不到再排队获取，性能更好一点Lock接口使用方法阻塞式加锁1234567// Lock l = someLock; l.lock(); try { // access the resource protected by this lock } finally { l.unlock(); }lock方法不抛出异常，但lock的具体实现可以进行死锁检测，从而抛出 unchecked exception。所以lock()使用时需要具体实现捕获加锁失败的异常进行处理。非阻塞加锁12345678910Lock lock = ...;if (lock.tryLock()) { try { // manipulate protected state } finally { lock.unlock(); }} else { // perform alternative actions}tryLock()方法不抛出异常，但lock的具体实现可以进行死锁检测，从而抛出 unchecked exception。所以lock()使用时需要具体实现捕获加锁失败的异常进行处理。限时加锁1234567891011121314try { Lock lock = ...; if (lock.tryLock(50, TimeUnit.MILLISECONDS)) { try { // manipulate protected state } finally { lock.unlock(); } } else { // perform alternative actions }} catch(InterruptedException e) { // process interrupted exception}加锁过程分为：直接加锁，返回true阻塞至加锁，返回true阻塞至线程中断，抛出异常阻塞至指定时间，返回falsetryLock(time, unit) 方法在被线程中断时会抛出异常，因而需要catch对应异常进行处理。ReentrantLockjdk中提供了ReentrantLock标准实现。ReentrantLock提供了公平锁和非公平锁两种策略，通过构造函数fair参数选择，默认获取非公平锁。一个线程最多可以获取Integer.MAX_VALUE把锁。ReentrantLock类的内部类Sync实现了一个可重入锁的Synchronizer，ReentrantLock的操作均会代理到Sync实现上。通过Sync子类实现公平锁和非公平锁。ReadWriteLock接口ReadWriteLock类是对于读写锁机制的抽象接口。设计关切点在于对于读多写少的场景进一步优化提高并发能力。提供一对方法分别后去读锁和写锁。1234interface ReadWriteLock { Lock readLock(); Lock writeLock();}ReentrantReadWriteLock类类似ReentrantLock，ReentrantReadWriteLock类提供了ReadWriteLock的标准实现，也提供公平锁和非公平锁两种策略。ReentrantReadWriteLock的内部类Sync实现了一个支持读写锁的Synchronizer，ReentrantReadWriteLock的ReadLock和WriteLock均会将操作代理到Sync实现上。通过Sync子类实现公平锁和非公平锁。","link":"/Hexo/2019/05/11/砖瓦集——Java-Lock/"},{"title":"砖瓦集——Java Thread Pool","text":"本文是关于 Thread Pool 对象的学习笔记。目标熟悉以下元素的概念和用法。ExecutorExecutorServiceScheduledExecutorServiceExecutorsThreadPoolExecutorSchedulePoolExecutorThreadFactoryRunnableCallableFutureRunnableFutureFutureTask概述上述各个类之间的关系如下：图中类分为两类：任务类和执行器类任务类Runnable：抽象一个没有返回值的任务Callable：抽象一个有返回值的任务Future：抽象一个异步执行任务，提供了查询进度、取消任务、获取执行结果等方法执行器类Executor: 顶层抽象接口。抽象执行已经提交的任务的对象。解耦了 task submission 和 task execution。ExecutorService: 扩展接口。主要提供三类管理接口接口：终止任务执行类、提交单任务类、提交批量任务类。Executors: 提供了大量创建其他对象的静态方法的工具类。ThreadPoolExecutor：线程池的具体实现类SchedulePoolExecutor：定义任务执行器的实现类ForkJoinPool：可以调节线程控制流的实现类ThreadFactory：抽象了创建线程的过程任务类Runnable抽象一个没有返回值的任务。和 Thread 一开始存在的抽象。没有参数没有返回值没有checked异常Callable抽象一个有返回值的任务。没有参数泛型类返回值可以抛出异常使用RunnableAdapter可以将Callable适配为Runnable。Executors提供了适配的工具方法。Future 和 RunnableFutureFuture是java异步编程的顶层抽象。RunnableFuture是Runnable和Future的聚合接口。提供了如下接口：检查是否执行结束的方法（isDone、isCanceled）等待执行结束的方法（无超时等待和有超时等待）获取执行结果的方法FutureTaskFuture的基础实现类，提供了把Runnable和Callable对象转换为Future对象的方法。ExecutorExecutor是顶层抽象接口。抽象执行已经提交的任务的对象。解耦了 task submission 和 task execution。Executor的执行策略Executor的实现者需要制定自己的执行策略。一个执行策略需要考虑如下要点：任务在什么线程执行任务以什么顺序执行，串行 vs 并发、FIFO vs LIFO、优先级多少个任务可以并发执行（即线程池大小是多少）等待队列长度是多少如何拒绝任务提交如何取消任务执行如何选择取消执行的任务如何处理任务执行的前置依赖和后置依赖单线程立即执行模式12345class DirectExecutor implements Executor { public void execute(Runnable r) { r.run(); }}Thread Per Task 执行模式12345class ThreadPerTaskExecutor implements Executor { public void execute(Runnable r) { new Thread(r).start(); }}生产者-消费者 执行模式使用 BlockingQueue创建一个任务队列，提交的任务加入队列，可以维护固定数目的线程从队列中消费任务。这一模式通常有不同的变种。根据队列长度和执行线程数目可以有：无边界队列，无限数目执行线程无边界队列，固定数目执行线程有边界队列，固定数目执行线程根据使用的队列类型可以有：使用优先级队列的工作模式使用FIFO队列的工作模式使用LIFO队列的工作模式使用双端队列的窃取工作模式ExecutorServiceExecutorService是扩展接口。扩展内容包括：shutdown的接口支持异步任务的接口（返回Future）支持批量执行的接口（invokeAll和invokeAny）ThreadPoolExecutor线程池的标准实现。主要关注点：提升大量异步任务执行的性能限制和管理资源（执行线程和任务消费）可以配置不同的参数实现不同的线程池。参数包括：core pool size 和 maximum pool size对任务提交的影响：已创建线程数小于core size，直接创建新线程，忽视已存在空闲线程已创建线程数介于core size 和 maximum size，任务入队，如果队列已满会直接新建线程设置值：core size 等于 maximum size 相当于 fixed size poolcore size 等于 0， maximum size 等于 Integer.MAX_VALUE，相当于 cached poolcore size 等于 maximum size 且等于 1， 相当于 single thread poolThreadFactory线程池使用ThreadFactory在需要时创建新线程。默认为Executors#defaultThreadFactory。可以通过ThreadFactory自定义：thread namethread groupprioritydaemonkeep-alive policyKeep-alive time 控制空闲线程存活时间默认只有线程数超出corePoolSize生效，通过allowCoreThreadTimeOut改变此行为QueuingThreadPoolExecutor使用BlockingQueue对象实现提交任务的排队行为。任务提交时的行为收到curentThreadNumber、corePoolSize、队列长度三者共同的影响。默认交互行为：curentThreadNumber &lt; corePoolSize, 创建新线程curentThreadNumber &gt;= corePoolSize 且队列未满， 任务入队curentThreadNumber &gt;= corePoolSize 且队列已满，新建线程三种排队策略：Direct handoffs无界队列（有资源耗尽风险）有界队列Reject任务提交被拒绝的情况：调用了Executor的shutdown方法使用有界队列且线程池和队列饱和ThreadPoolExecutor提供了不同拒绝策略：AbortPolicyCallerRunsPolicyDiscardPolicyDiscardOldestPolicyHook methodsThreadFactory提供了可以覆盖的钩子函数：beforeExecuteafterExecuteterminatedFinalizationThreadFactory实现了finalize方法，线程池回收的条件没有被引用线程池内所有线程被销毁未了防止线程死锁后导致线程池内存无法释放，最好设置 keepAliveTime allowCoreThreadTimeOut确保线程空闲一段时间后会被销毁。ScheduledExecutorService 和 ScheduledThreadPoolExecutorScheduledExecutorService接口扩展了ExecutorService的接口，支持如下两种行为：支持延迟执行（schedule方法）支持间隔执行（scheduleAtFixedRate方法）ScheduledThreadPoolExecutor类ScheduledExecutorService的标准实现类。ScheduledThreadPoolExecutor中有三类接口：来自Executor和ExecutorService的方法（转发到schedule方法，delay为0）ScheduledExecutorService的schedule方法（指定delay）ScheduledExecutorService的scheduleAtFixedRate和scheduleWithFixedDelay间隔执行对于间隔执行的情况，收到task执行时间、initialDelay和period的关系影响task执行的开始时间序列默认是：initialDelay， initialDelay+ N * periodtask不会并发执行，而是按序执行task执行时间大于period时，每个task开始时间可能会晚于预定序列时间task执行异常，整个执行序列停止","link":"/Hexo/2019/05/10/砖瓦集——Java-Thread-Pool/"},{"title":"砖瓦集——Java Synchronizer","text":"本文是关于 AQS 框架的学习笔记。目标了解java中关于synchronizer的实现。背景知识CAS操作系统的CAS指令不可中断原子操作CAS用来设计无锁数据结构（lock-free）。Unsafe类Java中Unsafe类的CAS方法AbstractQueuedSynchronizerAbstractQueuedSynchronizer 提供了实现Java中 Synchronizer的框架。AbstractOwnableSynchronizer类AbstractQueuedSynchronizer的父类，实现了 ownership 概念的顶层抽象类。用途：实现锁的基础实现各种 synchronizer 基础AbstractOwnableSynchronizer就是一个持有线程对象的对象。AbstractQueueSynchronizer类JDK对AbstractQueueSynchronizer类的定位：Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues.stateAbstractQueueSynchronizer使用一个 volatile int 表示同步状态，通过getState, setState, comparseAndSetState 三个方法管理。mode默认 互斥（exclusive） 模式支持 共享（shared） 模式ConditionObject提供了Condition 接口实现： 内部类ConditionObject。同步控制接口对应两种mode和加锁过程是否可中断提供三组synchronization control API：互斥模式，忽略中断exclusive mode, ignoring interrupts12public final void acquire(int arg) {}public final boolean release(int arg) {}互斥模式，允许中断exclusive mode, aborting if interrupted1234public final void acquireInterruptibly(int arg) throws InterruptedException {}public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException {}共享模式，忽略中断shared mode, ignoring interrupts12public final void acquireShared(int arg) {}public final boolean releaseShared(int arg) {}共享模式，允许中断shared mode, aborting if interrupted1234public final void acquireSharedInterruptibly(int arg) throws InterruptedException {}public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException {}此外还提供了查询线程队列和ConditionObject上等待状态的方法。重写协议子类通过重写的如下方法使用12345tryAcquiretryReleasetryAcquireSharedtryReleaseSharedisHeldExclusively子类重写原则：线程安全执行时间短不可阻塞其他方法不可重写（被声明为final）","link":"/Hexo/2019/05/12/砖瓦集——Java-Synchronizer/"},{"title":"微服务监控告警——实现篇","text":"背景功能篇里描述了我们的监控告警系统需要具备的基本能力。围绕这些基本能力，我们需要制定一个可以实现的方案。健康监控健康监控选择使用spring-boot-actuator配合spring-boot-admin实现。具体可以参见环境监控环境监控部分的工具选择为：使用spring-boot-actuator作为metrics采集器使用micrometer将actuator metrics转换为prometheus可以使用的metrics使用prometheus作为存储引擎和查询引擎使用grafana作为可视化工具业务微服务引入spring-boot-actuatorbuild.gradle中增加依赖：1234567dependencies { // monitor compile(\"org.springframework.boot:spring-boot-starter-actuator\") // ...}application.yml增加配置：123456789management: endpoints: web: exposure: include: auditevents,conditions,configprops,env,health,info,integrationgraph,loggers,liquibase,metrics,mappings,threaddump,heapdump,logfile,prometheus exclude: shutdown endpoint: health: show-details: ALWAYS对actuator endpoints配置security policy。TBD访问 &lt;HOSTNAME&gt;/actuator 验证actuator端点, 成功的情况下会出现如下列表：1234{\"_links\": { {\"self\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator\",\"templated\":false},\"auditevents\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/auditevents\",\"templated\":false},\"health-component-instance\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/health/{component}/{instance}\",\"templated\":true},\"health\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/health\",\"templated\":false},\"health-component\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/health/{component}\",\"templated\":true},\"conditions\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/conditions\",\"templated\":false},\"configprops\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/configprops\",\"templated\":false},\"env\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/env\",\"templated\":false},\"env-toMatch\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/env/{toMatch}\",\"templated\":true},\"info\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/info\",\"templated\":false},\"loggers\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/loggers\",\"templated\":false},\"loggers-name\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/loggers/{name}\",\"templated\":true},\"heapdump\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/heapdump\",\"templated\":false},\"threaddump\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/threaddump\",\"templated\":false},\"prometheus\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/prometheus\",\"templated\":false},\"metrics-requiredMetricName\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/metrics/{requiredMetricName}\",\"templated\":true},\"metrics\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/metrics\",\"templated\":false},\"mappings\":{\"href\":\"https://&lt;HOSTNAME&gt;/actuator/mappings\",\"templated\":false}}}}业务微服务引入micrometerbuild.gradle中增加依赖：1234567dependencies { // monitor compile 'io.micrometer:micrometer-registry-prometheus:latest.release' // ...}application.yml的management.endpoints.web.exposure增加prometheus。访问https://&lt;HOSTNAME&gt;/actuator/prometheus验证，成功情况下应该出现如下内容：12345678910111213141516# HELP system_cpu_count The number of processors available to the Java virtual machine# TYPE system_cpu_count gaugesystem_cpu_count 4.0# HELP process_uptime_seconds The uptime of the Java virtual machine# TYPE process_uptime_seconds gaugeprocess_uptime_seconds 347.673# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next# TYPE jvm_gc_memory_allocated_bytes_total counterjvm_gc_memory_allocated_bytes_total 7.6690036E8# HELP process_files_open_files The open file descriptor count# TYPE process_files_open_files gaugeprocess_files_open_files 123.0# HELP tomcat_global_error_total # TYPE tomcat_global_error_total countertomcat_global_error_total{name=&quot;http-nio-8080&quot;,} 6.0...Prometheus配置增加业务服务的jobPrometheus无法和部署在PCF上的Eureka集成，因而选择在一台可以访问公网的HOST上部署prometheus-server。并对每个按照上述部署的微服务增加对应的抓取指标的JOB配置。12345678scrape_configs: - job_name: 'actuator-client' metrics_path: '/actuator/prometheus' scrape_interval: 15s static_configs: - targets: ['&lt;HOSTNAME&gt;']# ...重启prometheus-server后可以在prometheus提供的简易web界面上调试，验证自己的微服务的指标数据是否能够成功抓取。配置业务服务的Grafana监控大盘TBDRabbitMQ监控准备RabbitMQ Admin账号生产环境的RabbitMQ使用PCF提供的服务实例，需要先在PCF上创建可以使用RabbitMQ Admin HTTP API的账号。1cf create-service-key My-RabbitMQ-Service rabbitmq_exporter使用如下命令获取RabbitMQ各个节点的元数据1cf service-key My-RabbitMQ-Service rabbitmq_exporter数据如下形式：123456789101112131415161718192021222324252627282930313233343536{ \"dashboard_url\": \"https://rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/#/login/HOSTNAME/PASSWORD\", \"hostname\": \"10.227.200.200\", \"hostnames\": [ \"10.227.200.200\" ], \"http_api_uri\": \"https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/\", \"http_api_uris\": [ \"https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/\" ], \"password\": \"PASSWORD\", \"protocols\": { \"amqp\": { \"host\": \"10.227.200.200\", \"hosts\": [ \"10.227.200.200\" ], \"password\": \"PASSWORD\", \"port\": 5672, \"ssl\": false, \"uri\": \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\", \"uris\": [ \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" ], \"username\": \"HOSTNAME\", \"vhost\": \"d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" } }, \"ssl\": false, \"uri\": \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\", \"uris\": [ \"amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a\" ], \"username\": \"HOSTNAME\", \"vhost\": \"d9a9c1ab-2383-400b-b5e8-3b84dabe221a\"}部署rabbitmq_exporter应用在Host 192.168.8.101上对每一个RabbitMQ节点部署一个rabbitmq_exporter应用，提供prometheus访问的metrics endpoint1RABBIT_URL=https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com RABBIT_USER=HOSTNAME RABBIT_PASSWORD=PASSWORD PUBLISH_PORT=9419 ./rabbitmq_exporter如果RabbitMQ节点会动态变化，则需要一个可以动态对每个节点启动一个RabbitMQ Exporter实例的策略。TBD在Prometheus Server的配置中增加rabbitmq_exporter的抓取配置。123456scrape_configs: - job_name: &apos;rabbitmq_exporter&apos; metrics_path: &apos;/metrics&apos; scrape_interval: 15s static_configs: - targets: [&apos;192.168.8.101:9419&apos;]对于RabbitMQ Exporter动态多节点的情况，需要进一步制定配置动态生成策略。TBD配置RabbitMQ的Grafana监控大盘Redis监控开发redis_exporter生产环境的Redis时PCF提供的服务实例，目前没有可以直接调用的API。为了获取Redis资源的运行状况，需要开发一个部署在PCF上的redis_exporter应用。redis_exporter应用类似rabbitmq_exporter，充当Prometheus和Redis之间的桥接器。redis_exporter API定义参见 使用Client Java构建Exporter程序。TBDredis_exporter 可以使用redis info 命令获取如下信息：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# Serverredis_version:4.0.11redis_git_sha1:00000000redis_git_dirty:0redis_build_id:74253224a862200credis_mode:standaloneos:Linux 4.9.93-linuxkit-aufs x86_64arch_bits:64multiplexing_api:epollatomicvar_api:atomic-builtingcc_version:6.3.0process_id:1run_id:349ceac52d741004776e02cf61650eff4d74e3f1tcp_port:6379uptime_in_seconds:587306uptime_in_days:6hz:10lru_clock:14467901executable:/data/redis-serverconfig_file:# Clientsconnected_clients:1client_longest_output_list:0client_biggest_input_buf:0blocked_clients:0# Memoryused_memory:852904used_memory_human:832.91Kused_memory_rss:4239360used_memory_rss_human:4.04Mused_memory_peak:929824used_memory_peak_human:908.03Kused_memory_peak_perc:91.73%used_memory_overhead:836198used_memory_startup:786456used_memory_dataset:16706used_memory_dataset_perc:25.14%total_system_memory:6246649856total_system_memory_human:5.82Gused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionmem_fragmentation_ratio:4.97mem_allocator:jemalloc-4.0.3active_defrag_running:0lazyfree_pending_objects:0# Persistenceloading:0rdb_changes_since_last_save:0rdb_bgsave_in_progress:0rdb_last_save_time:1557831710rdb_last_bgsave_status:okrdb_last_bgsave_time_sec:0rdb_current_bgsave_time_sec:-1rdb_last_cow_size:413696aof_enabled:0aof_rewrite_in_progress:0aof_rewrite_scheduled:0aof_last_rewrite_time_sec:-1aof_current_rewrite_time_sec:-1aof_last_bgrewrite_status:okaof_last_write_status:okaof_last_cow_size:0# Statstotal_connections_received:43total_commands_processed:110instantaneous_ops_per_sec:0total_net_input_bytes:80005total_net_output_bytes:245646instantaneous_input_kbps:0.00instantaneous_output_kbps:0.00rejected_connections:0sync_full:0sync_partial_ok:0sync_partial_err:0expired_keys:0expired_stale_perc:0.00expired_time_cap_reached_count:0evicted_keys:0keyspace_hits:52keyspace_misses:0pubsub_channels:0pubsub_patterns:0latest_fork_usec:248migrate_cached_sockets:0slave_expires_tracked_keys:0active_defrag_hits:0active_defrag_misses:0active_defrag_key_hits:0active_defrag_key_misses:0# Replicationrole:masterconnected_slaves:0master_replid:1c5eaf06e802ee89d4f9e8b68788948dbba9c88amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0# CPUused_cpu_sys:349.49used_cpu_user:71.78used_cpu_sys_children:0.00used_cpu_user_children:0.00# Clustercluster_enabled:0# Keyspacedb0:keys=2,expires=0,avg_ttl=0Prometheus配置增加抓取redis_exporter的jobTBD配置Redis的Grafana监控大盘DB监控Azure Dashboard告警及处理业务异常告警项目生产环境使用Splunk处理log数据。团队使用Webex Teams作为沟通工具。功能篇里描述的业务异常告警采用如下方式实现。定义Splunk搜索异常的查询语句定义Splunk Alert，选择webhook作为trigger action实现Splunk Webhook的Target Endpoint接收Splunk Alert Message（TBD）Splunk Webhook Target Endoint发送Message到Webex Teams群组配置Splunk Alert在splunk里定义我们关心的Exception查询语句，并保存为Alert Rule。Alert配置里设置Trigger Action，使用Webex Teams Webhook。实现Splunk Alert Webex Bridge因为Splunk不支持外网webhook，所以只能使用Splunk发送消息到webex teams，再由webex teams发送消息给bridge的方法。实现一个Bridge应用，定义接收来自splunk alert的Target Endpoint（TODO）。Target Endpoint接口定义如下：URL: POST /bridge/splunkRequest Body:123456789101112{ \"result\": { \"sourcetype\" : \"mongod\", \"count\" : \"8\" }, \"sid\" : \"scheduler_admin_search_W2_at_14232356_132\", \"results_link\" : \"http://web.example.local:8000/app/search/@go?sid=scheduler_admin_search_W2_at_14232356_132\", \"search_name\" : null, \"owner\" : \"admin\", \"app\" : \"search\"}Target Endpoint接到Splunk Alert后，需要将Alert按照定义好的Webex Teams消息的格式，调用Webex Teams的Create Message API，发送消息到特定Channel。配置Splunk Alert Throttle策略Splunk提供了Alert Throttle功能，使用此功能实现Alert发送成功后静默一段时间的策略。Metrics告警系统的监控部分构建了Metrics监控能力，对于Metrics的Alert实现方法如下：使用Grafana管理Metrics Alert Rule使用Grafana Webhook Notification Channel完成通知环节实现Grafana Alert Bridge应用，接收Webhook通知Grafana Alert Bridge负责转发alert通知到Webex Teams告警处理当告警出现，开发跟进alert的流程需要结合Webex Teams进行。实现方案选择如下：配置Webex Teams Webhook功能实现Webex Teams Webhook Target Endpoint接收消息Webex Teams Webhook Target Endpoint跟进Alert的类型，选择处理流程当Alert是来自Splunk的Exception Alert时，记录处理人信息当Alert是来自Grafana的Metrics Alelrt时，记录处理人信息，调用Grafana Alert API，暂停对应Alert一段时间当接到处理结束信息，跟进Alert类型选择处理流程当Alert是来自Splunk的Exception Alert时，记录处理结果信息当Alert是来自Grafana的Metrics Alelrt时，记录处理结果信息，调用Grafana Alert API，恢复对应Alert一段时间Webex Teams Webhook配置TODOTarget Endpoint接口定义URL： POST /bridge/webex/alertRequest Body:1234567891011121314151617181920{ \"id\": \"Y2lzY29zcGFyazovL3VzL1dFQkhPT0svZjRlNjA1NjAtNjYwMi00ZmIwLWEyNWEtOTQ5ODgxNjA5NDk3\", \"name\": \"New message in 'Project Unicorn' room\", \"resource\": \"messages\", \"event\": \"created\", \"filter\": \"roomId=Y2lzY29zcGFyazovL3VzL1JPT00vYmJjZWIxYWQtNDNmMS0zYjU4LTkxNDctZjE0YmIwYzRkMTU0\", \"orgId\": \"OTZhYmMyYWEtM2RjYy0xMWU1LWExNTItZmUzNDgxOWNkYzlh\", \"createdBy\": \"Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY\", \"appId\": \"Y2lzY29zcGFyazovL3VzL0FQUExJQ0FUSU9OL0MyNzljYjMwYzAyOTE4MGJiNGJkYWViYjA2MWI3OTY1Y2RhMzliNjAyOTdjODUwM2YyNjZhYmY2NmM5OTllYzFm\", \"ownedBy\": \"creator\", \"status\": \"active\", \"actorId\": \"Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY\", \"data\":{ \"id\": \"Y2lzY29zcGFyazovL3VzL01FU1NBR0UvOTJkYjNiZTAtNDNiZC0xMWU2LThhZTktZGQ1YjNkZmM1NjVk\", \"roomId\": \"Y2lzY29zcGFyazovL3VzL1JPT00vYmJjZWIxYWQtNDNmMS0zYjU4LTkxNDctZjE0YmIwYzRkMTU0\", \"personId\": \"Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY\", \"personEmail\": \"matt@example.com\", \"created\": \"2015-10-18T14:26:16.000Z\" }}Target Endpoint 需要分析携带的消息内容，跟进消息内容解析出对应的指令，然后执行对应操作。目前需要支持的指令有：process #&lt;Alert Id&gt;finished #&lt;Alert Id&gt;validated #&lt;Alert Id&gt;release #&lt;Alert Id&gt;","link":"/Hexo/2019/04/28/微服务监控告警——实现篇/"},{"title":"砖瓦集——Java并发编程演变史","text":"Java多线程演变时间轴JDK 1.0，基础线程模型，采用抢占式调度策略，使用stop/resume/suspend等方法进行线程间协作JDK 1.2，引入ThreadLocal，废除stop/resume/suspendJDK 1.4，引入NIOJDK 1.5，引入concurrent包，确立happens-before内存模型JDK 6.0，锁优化JDK 7.0，完善了并发流程控制，fork-join框架","link":"/Hexo/2019/05/11/砖瓦集——Java并发编程演变史/"},{"title":"砖瓦集——Java Thread","text":"本文是关于 Thread 对象的学习笔记。Thread开始的地方jdk 1.0起存在的两个类：Thread和Runnable，是java 1.0开始提供给用户代码使用线程的方式。Thread基础操作系统的进程与线程计算机硬件资源包括寄存器、CPU、主存、IO设备，操作系统负责管理计算机硬件资源。操作系统具有三大基本抽象：文件（抽象了IO设备）、虚存抽象（抽象了主存和磁盘IO设备）、进程抽象（抽象了处理器和虚存）。应用程序以进程的方式运行，应用程序的视角下：独占处理器独占虚拟地址空间操作系统启动后需要常驻内存，所以进程的虚拟地址空间分为两种：内核地址空间（所有进程共享，但应用程序不可访问）用户地址空间用户地址空间分区：环境变量区命令行参数区栈内存映射段堆BSS段（未初始化的全局变量和静态局部变量）Data段（已初始化的全局变量和静态局部变量）Text段（存放应用程度代码）保留区进程和线程区别：进程是操作系统资源分配的基本单位，进程间的地址空间是隔离的线程是CPU调度的基本单位，线程间共享进程的地址空间进程调度和线程调度区别：进程调度切换上下文时包括：寄存器、程序状态字、用户地址空间（加载新程序的代码到Text段，初始化Data段和BSS段）线程调度切换上下文只有：寄存器、程序状态字、用户地址空间的栈区域因而线程切换消耗比进程切换消耗少。JVM进程与Threadjvm进程：执行java命令启动一个jvm进程jvm通过Thread类提供应用程序使用线程资源的能力jvm调度用户线程即执行Thread对象的过程jvm调度线程终止条件：调用System.exit所有用户线程结束（正常执行结束或异常结束）daemon：Thread分为用户线程和守护线程主线程为用户线程启动线程前调用Thread#setDaemon创建守护线程守护线程在jvm进程退出时结束Thread ID：每个线程创建时自动分配一个自增的Thread IDThread Name：创建线程时可以为线程命名匿名线程会按照默认策略生成一个“Thread-“的名字优先级：线程的优先级影响jvm调度线程的情况Thread对象Thread类Thread类里的关键成员分类：核心数据结构：name、匿名线程序列号、priority、daemon与调度器交互：start、yield、run、sleep、alive与其他线程交互：suspend（弃用）、resume（弃用）、join、interrupt与对象锁交互：holdsLock、wait、notify与线程组相关：activeCount、enumerateThreadLocal相关：threadLocals、inheritableThreadLocals调试相关：ThreadLocal类每个代表线程的Thread对象里存在包访问的ThreadLocalMap实例ThreadLocal通过维护Thread里的ThreadLocalMap给每个线程维护一个变量的副本ThreadLocal实现了 Thread Confine PatternThreadLocalMap类ThreadLocalMap是一个用Entry数组实现的hash map每个Entry都是继承WeakReference&lt;ThreadLocal&lt;?&gt;&gt;的弱引用，所以当ThreadLocal#set(null)时该变量可以被gc回收向ThreadLocalMap增加项时可能rehashrehash时先清除不用的值再考虑数组加倍创建线程的两种方法创建Thread的子类使用Runnable对象实例化Thread对象阻塞线程的方法调用Thread#sleep()调用Thread#yield()方法让出资源调用阻塞方法调用同步方法申请锁等待notify调用suspend方法被JVM调度线程生命周期调用new Thread时，线程处于新建态调用Thead#start()方法，线程处于就绪态调用Thead#run()方法（由JVM调用），线程处于运行态调用Thread#stop()方法，线程处于死亡态调用Thread#sleep()或Thread#yield()方法，或阻塞方法、或申请锁、或等待通知、或调用suspend方法、或者被JVM调度释放时，线程处于阻塞态Runnablejdk对此接口的定位为：This interface is designed to provide a common protocol for objects that wish to execute code while they are active.关于Runnable接口的两个正确用法：用Runnable实例来创建线程避免创建Thread子类的方式Runnable实例的生命周期应该和执行时间一直，执行结束就被销毁基于Thread/Runnable的多线程编程利用线程编程时，基本的场景是：开启一个线程执行某个任务，执行过程中监测到不符合条件的状态阻塞线程从而让出CPU，当条件改变满足继续执行时唤起线程继续执行。下面代码展示了使用Thread的suspend和resume完成这个场景的方法。123456789101112131415public class Main { private static volatile boolean condition = false; public static void main(String args[]) throws InterruptedException { Thread t = new Thread(() -&gt; { System.out.println(\"do part 1\"); if(!condition) { Thread.currentThread().suspend(); } System.out.println(\"do part 2\"); }); t.start(); System.out.println(\"do something\"); condition = true; Thread.sleep(2000); // 移除这行代码，可能resume比suspend先执行 t.resume(); }}但是由于设计上的缺陷，执行时resume必须在suspend之后执行，且成对出现，才能正确执行。但并没有可以保证resume在suspend之后执行的方法，所以这对API很难保证使用正确，容易导致线程假死。被弃用的stopstop在终止线程时会强制中断线程的执行，并且还会释放这个线程持有的所有的锁对象。这一现象会被其它因为请求锁而阻塞的线程看到，使他们继续向下执行，可能就会造成数据的不一致。例子 从A账户向B账户转账X元这一过程有三步操作，第一步是从A账户中减去X元，假如到这时线程就被stop了，那么这个线程就会释放它所取得锁，然后其他的线程继续执行，这样A账户就莫名其妙的少了X元而B账户也没有收到钱被弃用的suspend/resumesuspend阻塞线程时不会释放线程持有的锁。因此存在两种情况：A 获得锁X后suspend，B需要获得锁X后才能resume A，造成死锁没有可以保证resume在suspend之后执行的方法，线程可能假死","link":"/Hexo/2019/05/10/砖瓦集——Java-Thread/"},{"title":"webpack的插件体系结构","text":"前置知识javascriptwebpack基本使用node.js异步编程基础环境信息webpack 1.13.2node.js 6.9.5关键词webpack插件体系Tapable.js正文内容引入webpack概括来讲是一个打包工具，但也不仅仅是一个打包工具。这个从它复杂繁多的配置项里就可见一斑。webpack不仅能完成前端代码的打包，配合其他工具，它能做的事情几乎没有边界。配合babel完成es6到es5代码的转码，配合webpack-dev-server完成代码serve及开发时的hot-reload，配合uglify.js完成代码混淆，配合vue-loader转换.vue文件实现vue的单文件组件特性。而webpack完成这一强大扩展性的核心在于其基于Tapable.js的插件体系结构。Tapable.js本质上是一个发布-订阅模式的具体实现。下面将从发布-订阅模式开始简要介绍webpack的插件结构。从发布-订阅模式谈起一个简单的发布-订阅模式中包括发布者，订阅者；发布者提供订阅方法和发布方法；订阅者提供发布回调方法。模拟一个简单的发布-订阅模式下面code展示了一个最简单的发布-订阅模式（推的形式）的实现。1234567891011121314151617181920212223// 发布者，的管理节点，维护订阅者列表，发布具体数据function Publisher() { this._subs = [];}// 订阅方法，callback是订阅者Publisher.prototype.subscribe = function(callback) { this._subs.push(callback);}// 发布方法, 发布者通过发布方法传递数据给订阅者Publisher.prototype.publish = function(data) { this._subs.forEach(function(sub) { sub(data); });}// 取消订阅方法，发布者移除某个订阅者Publisher.prototype.unsubscribe = function(callback) { this._subs = this._subs.filter(function(sub) { return sub !== callback; });}在这个简单模型里，因为javascript里函数也是对象，所以可以将订阅者和发布回调方法使用同一个callback函数实现。发布者还可以提供一个可选的取消订阅方法供客户代码取消特定订阅者，不再继续接受发布者发布的数据。浏览器中的发布-订阅模式真实环境中发布-订阅模式随处可见。最常见的是浏览器里的事件机制。EventTarget是发布者，EventTarget.prototype.addEventListener是订阅方法，EventTarget.prototype.dispatchEvent是发布方法，EventTarget.prototype.removeEventListener是取消订阅方法。每一个继承了EventTarget的对象都是发布者。比较需要留意的是Element,window,document和XMLHttpRequest四个对象继承了EventTarget。此外node.js的EventEmitter及继承了EventEmitter的对象也是发布者的实现。Tapable.js插件引擎Tapable.js是webpack实现的一个插件引擎，本质上也是一个发布者的实现。每个Tapable类的实例都是一个发布者，内部维护了命名插件列表。同时Tapable类提供了一套管理订阅者的API，提供不同形式的调用发布回调方法。作为webpack实现插件结构的基础类，我们有必要熟悉这个类提供的基础能力。下面将简要介绍Tapable.js的API的功能。每个API通过一个代码块来描述，每个代码块包含四个部分：API的功能描述API定义的方法签名一段测试代码测试代码的示例输出Tapable类定义1234567891011// 构造函数， 初始化命名插件列表function Tapable() {}// 注册插件Tapable.prototype.plugin = function(name, fn) {}// 应用插件，代理到插件实例的apply方法Tapable.prototype.apply = function() {} // 重置同步插件列表开始下标Tapable.prototype.restartApplyPluginsapplyPlugins123456789101112131415161718192021222324// 调用一个同步插件列表Tapable.prototype.applyPlugins = function(name) {}// 对于如下测试代码：var tapable = new Tapable();tapable.plugin('applyPlugins', function() { console.log('this is plugin 1');})tapable.plugin('applyPlugins', function() { console.log('this is plugin 2');})tapable.plugin('applyPlugins', function() { console.log('this is plugin 3');})tapable.applyPlugins('applyPlugins');// 输出为// this is plugin 1// this is plugin 2// this is plugin 3applyPluginsWaterfall1234567891011121314151617181920212223242526272829// 链式调用一个同步插件列表, 以init为初始值链式调用一个同步插件列表，列表中每个插件的返回值成为下一个插件的第一个参数Tapable.prototype.applyPluginsWaterfall = function(name, init) {}// 对于如下测试代码：var tapable = new Tapable();tapable.plugin('applyPluginsWaterfall', function(value) { console.log('this is plugin 1', ' i get value: ' + value++); return value;})tapable.plugin('applyPluginsWaterfall', function(value) { console.log('this is plugin 2', ' i get value: ' + value++); return value;})tapable.plugin('applyPluginsWaterfall', function(value) { console.log('this is plugin 3', ' i get value: ' + value++); return value;})var last = tapable.applyPluginsWaterfall('applyPluginsWaterfall', 0);console.log('the last value: ' + last);// 输出为：// this is plugin 1 i get value: 0// this is plugin 2 i get value: 1// this is plugin 3 i get value: 2// the last value: 3applyPluginsBailResult1234567891011121314151617181920212223242526// 调用一个同步插件列表，第一个返回非undefinded的插件可提前返回Tapable.prototype.applyPluginsBailResult = function() {}// 对于如下测试代码：var tapable = new Tapable();tapable.plugin('applyPluginsBailResult', function() { console.log('this is plugin 1');})tapable.plugin('applyPluginsBailResult', function() { console.log('this is plugin 2'); return 2;})tapable.plugin('applyPluginsBailResult', function() { console.log('this is plugin 3');})var last = tapable.applyPluginsBailResult('applyPluginsBailResult');console.log('the last value: ' + last);// 输出为// this is plugin 1// this is plugin 2// the last value: 2applyPluginsAsync12345678910111213141516171819202122232425262728293031323334353637383940// 链式调用一个异步插件列表，上一个插件执行结束后执行下一个插件Tapable.prototype.applyPluginsAsync = functoin(name) {}Tapable.prototype.applyPluginsAsyncSeries = Tapable.prototype.applyPluginsAsync// 对于如下测试代码：var tapable = new Tapable();tapable.plugin('applyPluginsAsync', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 1 with delay: ' + delay ); callback(); }, delay);})tapable.plugin('applyPluginsAsync', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 2 with delay: ' + delay ); callback(); }, delay);})tapable.plugin('applyPluginsAsync', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 3 with delay: ' + delay ); callback(); }, delay);})tapable.applyPluginsAsync('applyPluginsAsync', function() { console.log('done');});// 输出为：// this is plugin 1 with delay: 365.28033813757423// this is plugin 2 with delay: 615.922299406326// this is plugin 3 with delay: 327.0493787299531// doneapplyPluginsAsyncWaterfall1234567891011121314151617181920212223242526272829303132333435363738394041// 链式调用一个异步插件列表，上一个插件执行结束后执行下一个插件，上一插件的值通过第一个参数传递到下一个插件Tapable.prototype.applyPluginsAsyncWaterfall = function(name, init, callback) {} // 对于如下测试代码:var tapable = new Tapable();tapable.plugin('applyPluginsAsyncWaterfall', function(value, callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 1 with delay: ' + delay ); callback(null, value + '-1'); }, delay);})tapable.plugin('applyPluginsAsyncWaterfall', function(value, callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 2 with delay: ' + delay ); callback(null, value + '-2'); }, delay);})tapable.plugin('applyPluginsAsyncWaterfall', function(value, callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 3 with delay: ' + delay ); callback(null, value + '-3'); }, delay);})tapable.applyPluginsAsyncWaterfall('applyPluginsAsyncWaterfall', '0', function(err, message) { console.log('the last message: ' + message); console.log('done');});// 输出为：// this is plugin 1 with delay: 293.49776146010197// this is plugin 2 with delay: 543.2495323181399// this is plugin 3 with delay: 932.6130373949233// the last message: 0-1-2-3// doneapplyPluginsParallel123456789101112131415161718192021222324252627282930313233343536373839404142434445// 并发调用一个异步插件列表，所有插件结束后返回Tapable.prototype.applyPluginsParallel = function(name) {}// 对于如下测试代码:var tapable = new Tapable();var totalDelay = 0;tapable.plugin('applyPluginsParallel', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 1 with delay: ' + delay ); totalDelay += delay; callback(); }, delay);})tapable.plugin('applyPluginsParallel', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 2 with delay: ' + delay ); totalDelay += delay; callback(); }, delay);})tapable.plugin('applyPluginsParallel', function(callback) { var delay = Math.random() * 1000; setTimeout(function() { console.log('this is plugin 3 with delay: ' + delay ); totalDelay += delay; callback(); }, delay);})tapable.applyPluginsParallel('applyPluginsParallel', function(err) { console.log('totalDelay: ' + totalDelay); console.log('done');});// 输出为：// this is plugin 2 with delay: 45.88772912860905// this is plugin 3 with delay: 353.1725171220388// this is plugin 1 with delay: 491.4572602446987// totalDelay: 890.5175064953467// doneapplyPluginsParallelBailResult1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 并发调用一个异步插件列表，所有插件结束后返回, 返回最后一个有返回值的插件的返回值Tapable.prototype.applyPluginsParallelBailResult = function(name, callback) {} // 对于如下测试代码:var tapable = new Tapable();var totalDelay = 0;tapable.plugin('applyPluginsParallelBailResult', function(callback) { var delay = Math.random() * 1000; console.log('this is plugin 1 with delay: ' + delay ); setTimeout(function() { totalDelay += delay; callback(); }, delay);})tapable.plugin('applyPluginsParallelBailResult', function(callback) { var delay = Math.random() * 1000; console.log('this is plugin 2 with delay: ' + delay ); setTimeout(function() { totalDelay += delay; var time = Date.now(); console.log('plugin 2 returns at time: '+ time); callback(null, time); }, delay);})tapable.plugin('applyPluginsParallelBailResult', function(callback) { var delay = Math.random() * 1000; console.log('this is plugin 3 with delay: ' + delay ); setTimeout(function() { totalDelay += delay; var time = Date.now(); console.log('plugin 3 returns at time: '+ time); callback(null, time); }, delay);})tapable.applyPluginsParallelBailResult('applyPluginsParallelBailResult', function(err, value) { console.log('totalDelay: ' + totalDelay); console.log('the last value: ' + value); console.log('done');});// 输出为:// this is plugin 1 with delay: 635.2381208798292// this is plugin 2 with delay: 347.9609880914285// this is plugin 3 with delay: 90.2209742134965// plugin 3 returns at time: 1506257839951// plugin 2 returns at time: 1506257840208// totalDelay: 1073.4200831847543// the last value: 1506257840208// done获取Tapable.js测试代码wepack的插件结构通过插件的方式组织代码webpack因为其宏大的愿景，为了满足各种情况下的使用需求，必须使用一个可扩展的方式来实现。现在我们知道webpack使用了插件的体系结构来实现的。实现其插件体系结构的核心是Tapable.js这个插件引擎。但是Tapable.js只提供了基础的插件插件核心，如何使用Tapable.js实现webpack繁多复杂的功能则是另一个内容庞大的话题。webpack中每一个继承了Tapable的类都是一个可通过插件扩展的节点。比较重要的类有：Compiler: 编译器抽象，顶层插件管理者Compilation：编译过程抽象Resolver： 路径解析过程抽象Parser： ast解析过程抽象NormalModuleFactory： 模块构建过程抽象Template： 编译结果输出抽象每个类所做的工作不是本文关注重点，按下不表。webpack通过webpack.config.js的plugins配置项将插件注册入口暴露给开发者。配置在plugins里的插件实例通过apply方法获得Compiler实例引用。Compiler管理着webpack顶层的生命周期。一个生命周期对应着一个命名插件列表。获得Compiler实例引用的插件可以在其不同生命周期注册新的回调。回调通过参数获取其他插件节点（包括Compilation，Resolver，NormalModuleFactory等）的实例。回调执行时可以在新持有的插件节点实例上注册新的回调。一个生命周期内注册的插件只能是还未执行的生命周期的插件，已执行过的生命周期上注册的新的插件不会被触发执行。要在特定生命周期上注册插件，我们需要先获得对应节点的实例。而获得得对应节点的实例我们可能需要通过该节点实例的管理者的特定生命周期间接获取。一个典型的webpack插件生命周期下面是一个典型的webpack插件的定义（来自webpack1.x documentation - how-to-write-a-plugin）。1234567891011function HelloWorldPlugin(options) { // Setup the plugin instance with options...}HelloWorldPlugin.prototype.apply = function(compiler) { compiler.plugin('done', function() { console.log('Hello World!'); });};module.exports = HelloWorldPlugin;一个插件通常在webpack.config.js配置文件里创建实例，如下所示（改自webpack1.x documentation - using-plugins）：12345module.exports = { plugins: [ new webpack.HelloWorldPlugin() ]};在执行构建命令：1$ webpack -c webpack.config.js时会执行compiler.apply方法，这个方法遍历执行所有配置的插件实例上的apply方法。HelloWorldPlugin插件实例会在compiler的done这一生命周期注册回调。当compiler通过上面描述的Tapable.js的applyXXX方法发布done这个事件时，HelloWorldPlugin实例注册的done回调会被执行。webpack本身就是由这种方式通过各种插件如同积木一样搭建起来，这些插件有决定require函数解析文件路径方式的，有决定全局变量查找方式的，有决定模块编译之后输出格式的，有决定抽取公共模块方式的…写在最后在以webpack为工具链核心的工作流里，了解webpack实现是很有必要的。webpack实现时是通过插件的架构组织的代码，其插件的核心则是Tapable.js这个模块。Tapable.js本质上又一个发布-订阅模式的变体。上文先解释了一个简单的发布订阅模式的实现，然后通过代码描述了Tapable.js的API功能，最后通过一个简单的插件的例子描述了一个webpack插件的生命周期——定义，实例化和执行。一些微小的工作，希望对大家有所帮助。相关资料webpack源码webpack 1.x DocumentationTapable.js源码","link":"/Hexo/2017/09/25/webpack的插件体系结构/"},{"title":"知其所以然-Binding_System_of_Vue","text":"目标 理解Vue如何根据data生成DOM及挂载到Document对象上 理解Vue如何实现更新data属性值时自动更新DOM 理解Vue如何实现v-*指令引入DOM更新浏览器构建DOM Tree，渲染视图，并提供DOM API更新视图。浏览器保证视图的渲染结果和DOM Tree中的数据同步。开发者经常会从服务器加载数据更新到视图上，或根据用户的交互改变视图。这些改变视图的方式可以抽象成改变视图状态数据（即数据驱动视图）。我们一般都会使用data object保存从服务器加载到的数据或记录用户交互的状态数据，然后把这些data object里的数据同步到DOM对象的各个属性值上，触发视图的更新。一般的做法是这样的：12345678&lt;div&gt; Hello,&lt;span id=&quot;name&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;script&gt; var name = &apos;f-12&apos;; $(&apos;#name&apos;).text(name);&lt;/script&gt;name代表data object（既可能是从服务器上加载的数据，也可能是用户交互产生的状态数据），当我们把值赋给DOM的属性（使用原生DOM API或jQuery)，修改视图后，data，object就和DOM的属性值没有关系了，假如我们再次更新name，DOM属性值并不会变化，因而视图也不会变化。我们必须再次修改DOM属性才可以更新视图，即每次状态数据发生变动时我们必须手动更新视图。手动更新DOM显得很繁琐。前端工程更加复杂，用户交互更加复杂，单页应用更加流行，产生了更多的状态数据，这些因素也凸显了手动更新DOM的缺点。Data BindingData Binding的思想就是建立data object和DOM对象之前的关系，使得我们修改data object上的属性值时自动完成DOM对象的更新。要完成这个特性，我们很自然想到了观察者模式（发布/订阅模式）观察者模式定义The Observer Pattern defines a one-to-many dependency between objects so that when one object changes state, all of its dependents are notified and updated automatically.原理Pull vs Pushjavascript有两种observer pattern的实现方式：pull和push。Push： observable状态更新时使用变更的数据作为参数调用observer注册的回调Pull： observable状态变更时简单通知observer更新，observer使用自身持有的observable引用获取感兴趣的状态。( Vue中使用的Pull方式实现的observer pattern )用到Observer的地方jQuery对象的on/trigger方法Node里EventEmitter的on/emmit方法DOM里EventTarget的onXXXVue的Data BindingReference: vuejs.orgWeb开发中比较频繁出现的场景是：有很多状态数据需要同步到DOM上（DOM操作，jQuery流行的主要因素）多个DOM对象用到同一个状态数据，状态发生变动时需要更新所有DOM(Data Binding，MVVM流行的推动力)本次我们主要关注Vue的Data Binding实现的方式。继续进行前，我们需要引入一个最简单的🌰。123&lt;div id=\"app\"&gt; This is a {{ message }}.&lt;/div&gt;1234567import Vue from 'vue';const vm = new Vue({ el: '#app', data: { message: 'Hello Vue.js!' }})Reference: vuejs.org这个代码段的效果是页面渲染时，message的值会自动同步到DOM中，当修改message时，DOM会同步更新。接下来，我们来探究一下这一切是怎么发生的。importnew Vue()之前，我们首先得引入Vue的库，我们使用ES6的import方式。import Vue from 'vue'执行时，会首先找到vue包，然后执行里面的index.js代码，将其中导出的对象绑定到Vue这个标识符上。这一行代码完成Vue类的定义，导出一个构造函数来供使用者实例化。import过程体现了Vue的扩展能力，提现了Vue支持自定义directive，filter，watch等特性的方式。但是这个不是我们这次的关注重点，略过不讲。有了Vue的构造函数，就可以用它进行实例化了。Vue实例化时做了很多事情，支撑起了Vue的运行时。debate Vue是库(lib)还是框架(framework) ?实例化过程el选项以下段落来自Vuejs官方文档对el选项的描述。Type: string | HTMLElementRestriction: only respected in instance creation via new.Details:Provide the Vue instance an existing DOM element to mount on. It can be a CSS selector string or an actual HTMLElement.After the instance is mounted, the resolved element will be accessible as vm.$el.If this option is available at instantiation, the instance will immediately enter compilation; otherwise, the user will have to explicitly call vm.$mount() to manually start the compilation.The provided element merely serves as a mounting point. Unlike in Vue 1.x, the mounted element will be replaced with Vue-generated DOM in all cases. It is therefore not recommended to mount the root instance to &lt;html&gt; or &lt;body&gt;.See also: Lifecycle Diagramel选项提供Vue实例对象的挂载点，最终Vue实例将编译出一个DOM对象替换el对象的DOM。el的值可以是一个选择器String也可以是一个DOM HTMLElement元素，这样提供我们动态挂载Vue实例对象的能力，可以先new Vue()时不提供el值，得到vm对象后动态决定挂载点，调用vm.$mount()进行手动挂载。data选项以下段落来自Vuejs官方文档对data选项的描述。Type: Object | FunctionRestriction: Only accepts Function when used in a component definition.Details:The data object for the Vue instance. Vue will recursively convert its properties into getter/setters to make it “reactive”. The object must be plain: native objects such as browser API objects and prototype properties are ignored. A rule of thumb is that data should just be data - it is not recommended to observe objects with its own stateful behavior.data选项的值可以是Object，一般在根实例中这样定义；可以是Function，组件中必须是Function。原因是javascript的对象是可变对象，这样做可以避免多个组件实例公用同样的对象引用。实例化过程中会执行_initData()，在这个过程的最后一步是observe过程，将data选项转化为响应式数据。转化结果是data对象的__ob__保存新建的Observer对象，且此__ob__.value属性保存data选项对象。同时会遍历data选项对象的每个键值，使用ES6的Object.defineProperty定义其Getter和Setter。如果键值也是对象，会递归调用observe函数，即observe(key)。完成observe调用后的this.$data结构1234567891011{ __ob__: { dep: { subs: [] } value: {} //即this.$data自身 vms: [] //所有持有此data对象的vm实例 }, get message() {} set message(newVal) {}}因为observe过程是在_initData()过程中发生，而这个过程又在new Vue(options)构造函数的执行中进行，所以一旦实例创建结束后，再往data上增加的新键值并不是响应式，因为没有经过observe过程转化为响应式属性。Vue解决这种场景的方式是提供了Vue.$set方法。Text Node中的mustache编译提取表达式NodeType识别Text Node正则表达式提取expressionsafe: \\{\\{((?:.|\\\\n)+?)\\}\\}unsafe: \\{\\{\\{((?:.|\\\\n)+?)\\}\\}\\}创建包装getter创建包装的getter函数时使用new Function(string)完成，string是上一步提取的表达式的值。包装过程中一个scope的概念，指的是当前组件上下文，对于root组件来说是undefined。这也是访问没有定义的变量时console里经常报错scope.xxx找不到等错误的原因。上面例子中的 This is a .提取后形成下面的tokens列表：12345678910[ {value: 'this is a '}, { html: false, // 是否由unsafe模式匹配到的 oneTime: false, // 稍后介绍 tag: true, // 是否由safe或unsafe模式匹配到的 value: 'message' // 匹配到的文本值 }, {value: '.'}]Text中的每一个mustache匹配到的文本将生成类似列表中第二个对象的一个token对象。其他token是由其余简单文本生成的。创建Text Node根据每个tag属性为true的token使用function processTextToken (token, options) {}处理，创建对应的Text Node对象并加入到一个新创建的DocumentFragment对象中。此过程中将进一步对token标记descriptor。mustache内部可能包含的过滤器调用也是在descriptor中标记。token.tag为false直接生成简单的Text Node。此时的token结构如下：12345678910111213141516{ html: false, oneTime: false, tag: true, value: 'message', descriptor: { name: 'text', // 表示当前token代表一个text node // directives/public/text预先定义的directive def: { bind() {}, update() {} }, expression: 'message', // 由token中的值生成的表达式 filters: undefined // 可能包含的过滤器调用 }}Link递归编译每个DOM节点时，会对每个node生成对应的linker函数，这些linker会最终组合成一个linker。编译过程结束后，调用这个函数会开始link过程。代码概括为compile(el, options)(this, el)。link过程会递归调用所有的linker。每个linker调用会创建一个Directive对象并添加到Vue实例的_directives数组中。12345678910this._directives.push( new Directive( descriptor, // 编译过程中token中标记的discriptor this, // 当前Vue实例 node, // 创建的对应DOM node对象 host, // 宿主DOM node scope, frag ));当所有的Directive对象添加到Vue实例的_directives数组中后，会遍历新增加的所有Directive，调用其上的_bind方法。（由于Vue提供了通过自定义Directive复用代码的方式，这里为了防止在实例化过程中调用到这些Directive的_bind方法，Vue通个Directive.discriptor.priority中保存自身优先级， link过程中创建的Directive对象都具有默认优先级。然后遍历前会现根据优先级排序。）如下代码所示：1234567var originalDirCount = vm._directives.lengthlinker()var dirs = vm._directives.slice(originalDirCount)sortDirectives(dirs)for (var i = 0, l = dirs.length; i &lt; l; i++) { dirs[i]._bind()}至此link过程完成了一半，继续进行下一半前，我们需要引入Directive类和Watcher类。一个directive对象将DOM Element和data中的属性链接起来，并在内部注册一个Watchre对象，在data属性更新时调用update函数更新DOM对象。123456789101112131415161718192021222324252627// 内部结构如下：{ vm: Object, // Vue实例 el: Object, // 根DOM descriptor: Object, // discriptor name: String, // discriptor.name expression: Object, // discriptor.expression arg: Object, // discriptor.arg modifiers: [], // discriptor.modifiers filters: [], // discriptor.filters literal: , _locked: Boolean, // _bound: Boolean, // intial bind后为true _listeners: [], // _host: Object, // context信息 _scope: Object, // context信息 _frag: Object // context信息}/** * @constructor */export default function Directive (descriptor, vm, el, host, scope, frag) {}Directive.prototype._bind = function () {}/** 其他一些方法 */一个Watcher对象封装一个表达式，收集该表达式的依赖项，在表达式的值发生变化时调用回调函数。123456789101112131415161718192021222324252627282930313233// 内部数据结构如下{ vm： Vue, // Vue实例 expression: String | Function, // 被封装的表达式，来自discriptor.expression cb: Function, id: Number, // 内部自增全局变量uid，批处理使用 active: Boolean, dirty: Boolean, // lazy watchers标志量 deps: [], // newDeps: [], depIds: Set, newDepIds: Set, prevError: null, // for async error stacks getter: Function, setter: Function, queued: Boolean, // for avoiding false triggers for deep and Array shallow: Boolean // for avoiding false triggers for deep and Array}/** * @constructor */export default function Watcher (vm, expOrFn, cb, options) {}Watcher.prototype.get = function() {} // 计算expression的值并重新计算依赖Watcher.prototype.set = function(value) {} // 先应用可能的filter然后设置对应属性值Watcher.prototype.beforeGet = function() {} // 设置全局Dep.target为当前Watcher实例，准备收集依赖Watcher.prototype.afterGet = function() {} //Watcher.prototype.update = function(shallow) {} // Subscriber接口，被Publisher调用，Vue的Publisher由Dep实现Watcher.prototype.run = function() {} // Batch job接口，被batcher调用Watcher.prototype.evalute = function() {}Watcher.prototype.addDep = function() {} //Watcher.prototype.depend = function() {} // 遍历调用deps上的dependWatcher.prototype.teardown = function() {} // 清楚一个watcher，遍历调用deps里的removeSub()移除对其的订阅在directive对象bind的过程中， 会删除el DOM上声明的v-*指令，然后将discriptor上定义的属性mixin到自身，并调用discriptor.bind()完成initial bind。然后会new一个Watcher对象，并初始化更新DOM，将data上的初始化值更新到DOM上（这里需要例外处理v-model，将input的inline value回写到data中）。此时我们生成的Directive和Watcher对象如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445{ _bound: true, _frag: undefined, _host: undefined, _listeners: null, _locked: false, _scope: undefined, _update() {}, _watcher: { // 每个directive对象都会持有一个watcher对象 id: 1, active: true, cb(val, oldVal) {}, deep: undefined, depIds: [1], deps: [Watcher], dirty: undefined, expression: &quot;message&quot;, filters: undefined, getter() {} newDepIds: [], newDeps: [], postProcess: null, preProcess: null, prevError: null, queued: false, scope: undefined, setter: undefined, shallow: false, twoWay: undefined, value: &quot;hello world&quot; }, arg: undefined, attr: &quot;data&quot;, // 因为是data选项中定义的属性，所以值为data，如果只是简单text则为textContent descriptor: Object, // token.descriptor bind: bind(), // token.descriptor.bind update(value) {}, // token.descriptor.update el: Text, // DOM中的Text类实例 expression: &quot;message&quot;, filters: undefined, literal: undefined, modifiers: undefined, name: &quot;text&quot;, // 标明此directive对象注册时key为text，自定义directive时将由Vue.directive(name, Object)提供name vm : Vue}依赖系统前面讲解link过程时，提到了收集依赖。所以一并讲解下Vue的依赖系统。依赖系统本质上是一个发布-订阅模式的实现。Watcher实现订阅者职责，Dep实现发布者职责，发布的内容是自身值的改变，Watcher对应的响应是使用依赖重新计算自己的值并调用回调函数。为此引入Dep类。一个Dep对象是一个发布者，可以被多个directive（实际上是directive里面的watcher）订阅。1234567891011121314// 内部结构{ id: Number, // 自增的uid subs: [] // 实现了update方法的对象}export default function Dep () {}Dep.target // 全局变量，标志当前收集依赖的Watcher对象Dep.prototyp.addSub = function() {} // 增加订阅者Dep.prototyp.removeSub = function() {} // 移除订阅者Dep.prototyp.depend = function() {} // 将自身增加当Dep.target的依赖中Dep.prototyp.notify = function() {} // 遍历调用subs里对象的update方法，即发布更新Binding流程下面使用流程图总结一下这个过程中的行为。Workshop debug vm.message = 'Goodbye World'时的执行时序指令处理Vue会根据写在template里的模板编译出DOM对象。template模板本身是html代码，Vue的功能通过写在html代码里的指令，mustache代码以及自定义tag实现。模板的编译本质上是手动创建DOM树的过程。Vue中指令主要有v-*指令以及指令，还有number, transition, keep-alive等属性指令，还有&lt;component&gt;&lt;/component&gt;等元素指令，还有自定义组件标签指令。Terminal指令v-if指令v-if compile开始前，我们需要小小修改下实例代码，如下。123&lt;div id=\"app\"&gt; This is a &lt;span v-if=\"show\"&gt;{{ message }}&lt;/span&gt;.&lt;/div&gt;12345678import Vue from 'vue';const vm = new Vue({ el: '#app', data: { show: true, message: 'Hello Vue.js!' }})结合之前讲的过程，直接从compile阶段开始。123456789101112131415161718192021222324252627function compileElement(el, options) { // preprocess textareas. // textarea treats its text content as the initial value. // just bind it as an attr directive for value. // ... var linkFn; var hasAttrs = el.hasAttributes(); var attrs = hasAttrs &amp;&amp; toArray(el.attributes); // check terminal directives (for &amp; if) if (hasAttrs) { linkFn = checkTerminalDirectives(el, attrs, options); } // check element directives if (!linkFn) { linkFn = checkElementDirectives(el, options); } // check component if (!linkFn) { linkFn = checkComponent(el, options); } // normal directives if (!linkFn &amp;&amp; hasAttrs) { linkFn = compileDirectives(attrs, options); } return linkFn;}上面代码会从el选项指示的挂载点div#app开始，可以断定，在实例代码中，会执行两次，第一次针对div#app, 第二次针对span。跳过对div#app的编译过程，直接看对span执行的过程。代码标明对指令的处理主要经过了两个过程：check和compile。其中check会分别检查terminal directive，element directive， component。其中terminal directive指的是v-*指令，element directive指类似&lt;component&gt;&lt;/component&gt;这样的自定义标签指令，component指令指自Vue组件。实例代码比较简单所以只会执行checkTerminalDirectives。12345678910111213141516171819202122232425262728function checkTerminalDirectives(el, attrs, options) { // skip v-pre // ... // skip v-else block, but only if following v-if // ... var attr, name, value, modifiers, matched, dirName, rawName, arg, def, termDef; for (var i = 0, j = attrs.length; i &lt; j; i++) { attr = attrs[i]; name = attr.name.replace(modifierRE, ''); if (matched = name.match(dirAttrRE)) { def = resolveAsset(options, 'directives', matched[1]); if (def &amp;&amp; def.terminal) { if (!termDef || (def.priority || DEFAULT_TERMINAL_PRIORITY) &gt; termDef.priority) { termDef = def; rawName = attr.name; modifiers = parseModifiers(attr.name); value = attr.value; dirName = matched[1]; arg = matched[2]; } } } } if (termDef) { return makeTerminalNodeLinkFn(el, dirName, value, options, termDef, rawName, arg, modifiers); }}这个过程会遍历element attribute node列表，name.match(dirAttrRE)来匹配到需要处理的v-*指令。这里dirAttrRE是正则表达式：/^v-([^:]+)(?:$|:(.*)$)/。对每个特定的terminal directive，def = resolveAsset(options, 'directives', matched[1])获取内置的指令def对象, 实例中即为def = resolveAsset(options, 'directives', 'if')。Terminal directive 的def对象在’src/directives/public/‘目录下定义，每个def对象定义了bind过程中调用的接口方法, 如下所示：12345678910{ priority: DEFAULT_TERMINAL_PRIORITY, terminal: true, bind() {}, update(value) {}, insert() {}, remove() {}, updateRef() {}, unbind() {}}这个def对象，讲解Text Node编译过程中也涉及到了，当时只有bind和update方法。v-if link编译完成后，将进行link过程。此过程和Text Node的link过程基本一致，最终会执行如下代码：1234567891011121314151617181920212223this._directives.push( new Directive( descriptor, // 编译过程中token中标记的discriptor this, // 当前Vue实例 node, // 创建的对应DOM node对象 host, // 宿主DOM node scope, frag ));// descriptor:{ arg: undefined, attr: 'v-if', def: {}, // 上文有详述，略去细节 expression: 'show', filters: undefined, modifiers: {} // 空对象 name: 'if', raw: 'show'}// node: &lt;span v-if=\"show\"&gt; {{ show }}&lt;/span&gt;v-if bind上面link过程结束后，会开始bind过程，具体请见上一节。v-if的bind过程中多态部分是执行v-if def对象上的bind() {}的过程。如下代码所示：123456789101112function bind() { var el = this.el; if (!el.__vue__) { // check else block // ... // check main block this.anchor = createAnchor('v-if'); replace(el, this.anchor); } else { // debug info }}这个过程其实就是简单的创建了一个空白的Text Node替换了&lt;span&gt;&lt;/span&gt;DOM元素，所以页面中开始出现会出现短暂地变成空白。但是createAnchor的设计意图可以深究一下，目前所知就是为了和后面的初始化update结合使用，update环节会获取show的值，根据值计算节点, 调用def.insert方法，将正式DOM插入到createAnchor所在位置。bind的其他过程同上节所示。v-for指令v-for指令的compile和link过程和v-if指令大致相同，区别仅在bind过程调用def.bind和def.update上。但是v--for指令有性能优化的问题要解决，比如列表更新时如何最少化DOM操作，如何进行实例缓存等。Vue使用diff算法解决列表渲染中列表动态变化的问题。其他v-*指令类似的处理，但是涉及不同情况的细节处理。可以细看src/directive/public/目录下的代码。Element指令&lt;component&gt;&lt;/component&gt;指令&lt;slot&gt;&lt;/slot&gt;指令这个也很简单，处理node attribute时检查slot属性，然后替换父节点内的name匹配的slot节点即可。Custom Component指令推荐阅读banama/abountVuejinks","link":"/Hexo/2016/09/19/知其所以然-Binding-System-of-Vue/"}],"tags":[{"name":"总结","slug":"总结","link":"/Hexo/tags/总结/"},{"name":"监控","slug":"监控","link":"/Hexo/tags/监控/"},{"name":"告警","slug":"告警","link":"/Hexo/tags/告警/"},{"name":"札记","slug":"札记","link":"/Hexo/tags/札记/"},{"name":"Spring","slug":"Spring","link":"/Hexo/tags/Spring/"},{"name":"SpringBootAdmin","slug":"SpringBootAdmin","link":"/Hexo/tags/SpringBootAdmin/"},{"name":"Monitoring","slug":"Monitoring","link":"/Hexo/tags/Monitoring/"},{"name":"微服务","slug":"微服务","link":"/Hexo/tags/微服务/"},{"name":"ALert","slug":"ALert","link":"/Hexo/tags/ALert/"},{"name":"Prometheus","slug":"Prometheus","link":"/Hexo/tags/Prometheus/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/Hexo/tags/RabbitMQ/"},{"name":"DDD","slug":"DDD","link":"/Hexo/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","link":"/Hexo/tags/领域驱动设计/"},{"name":"最佳实践","slug":"最佳实践","link":"/Hexo/tags/最佳实践/"},{"name":"TODO","slug":"TODO","link":"/Hexo/tags/TODO/"},{"name":"Java","slug":"Java","link":"/Hexo/tags/Java/"},{"name":"线程","slug":"线程","link":"/Hexo/tags/线程/"},{"name":"并发","slug":"并发","link":"/Hexo/tags/并发/"},{"name":"fork","slug":"fork","link":"/Hexo/tags/fork/"},{"name":"join","slug":"join","link":"/Hexo/tags/join/"},{"name":"锁","slug":"锁","link":"/Hexo/tags/锁/"},{"name":"Lock","slug":"Lock","link":"/Hexo/tags/Lock/"},{"name":"线程池","slug":"线程池","link":"/Hexo/tags/线程池/"},{"name":"Synchronizer","slug":"Synchronizer","link":"/Hexo/tags/Synchronizer/"},{"name":"webpack","slug":"webpack","link":"/Hexo/tags/webpack/"},{"name":"javascript","slug":"javascript","link":"/Hexo/tags/javascript/"},{"name":"源码分析","slug":"源码分析","link":"/Hexo/tags/源码分析/"},{"name":"插件体系","slug":"插件体系","link":"/Hexo/tags/插件体系/"},{"name":"Vue","slug":"Vue","link":"/Hexo/tags/Vue/"},{"name":"Javascript","slug":"Javascript","link":"/Hexo/tags/Javascript/"},{"name":"Web","slug":"Web","link":"/Hexo/tags/Web/"}],"categories":[]}