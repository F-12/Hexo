---
title: 微服务监控告警——实现篇
date: 2019-04-28 17:14:13
toc: true
thumbnail: /images/banner.jpg
tags:
    - Monitoring
    - 监控
    - 微服务
---

# 背景
功能篇里描述了我们的监控告警系统需要具备的基本能力。围绕这些基本能力，我们需要制定一个可以实现的方案。


# 健康监控

健康监控选择使用spring-boot-actuator配合spring-boot-admin实现。  
具体可以参见 {% post_link 微服务监控告警——使用SpringBootAdmin对服务进行实时可视化管理.md %}

# 环境监控

环境监控部分的工具选择为：
- 使用spring-boot-actuator作为metrics采集器
- 使用micrometer将actuator metrics转换为prometheus可以使用的metrics
- 使用prometheus作为存储引擎和查询引擎
- 使用grafana作为可视化工具

## 业务微服务引入spring-boot-actuator

`build.gradle`中增加依赖：
```groovy

dependencies {
	// monitor
	compile("org.springframework.boot:spring-boot-starter-actuator")

    // ...
}
```

`application.yml`增加配置：

```YAML
management:
  endpoints:
    web:
      exposure:
        include: auditevents,conditions,configprops,env,health,info,integrationgraph,loggers,liquibase,metrics,mappings,threaddump,heapdump,logfile,prometheus
        exclude: shutdown
  endpoint:
    health:
      show-details: ALWAYS
```

对`actuator` endpoints配置security policy。

TBD

访问 `<HOSTNAME>/actuator` 验证actuator端点, 成功的情况下会出现如下列表：
```json
{
"_links": {    
{"self":{"href":"https://<HOSTNAME>/actuator","templated":false},"auditevents":{"href":"https://<HOSTNAME>/actuator/auditevents","templated":false},"health-component-instance":{"href":"https://<HOSTNAME>/actuator/health/{component}/{instance}","templated":true},"health":{"href":"https://<HOSTNAME>/actuator/health","templated":false},"health-component":{"href":"https://<HOSTNAME>/actuator/health/{component}","templated":true},"conditions":{"href":"https://<HOSTNAME>/actuator/conditions","templated":false},"configprops":{"href":"https://<HOSTNAME>/actuator/configprops","templated":false},"env":{"href":"https://<HOSTNAME>/actuator/env","templated":false},"env-toMatch":{"href":"https://<HOSTNAME>/actuator/env/{toMatch}","templated":true},"info":{"href":"https://<HOSTNAME>/actuator/info","templated":false},"loggers":{"href":"https://<HOSTNAME>/actuator/loggers","templated":false},"loggers-name":{"href":"https://<HOSTNAME>/actuator/loggers/{name}","templated":true},"heapdump":{"href":"https://<HOSTNAME>/actuator/heapdump","templated":false},"threaddump":{"href":"https://<HOSTNAME>/actuator/threaddump","templated":false},"prometheus":{"href":"https://<HOSTNAME>/actuator/prometheus","templated":false},"metrics-requiredMetricName":{"href":"https://<HOSTNAME>/actuator/metrics/{requiredMetricName}","templated":true},"metrics":{"href":"https://<HOSTNAME>/actuator/metrics","templated":false},"mappings":{"href":"https://<HOSTNAME>/actuator/mappings","templated":false}}
}}
```

## 业务微服务引入micrometer

`build.gradle`中增加依赖：
```groovy

dependencies {
	// monitor
    compile 'io.micrometer:micrometer-registry-prometheus:latest.release'

    // ...
}
```

`application.yml`的`management.endpoints.web.exposure`增加`prometheus`。

访问`https://<HOSTNAME>/actuator/prometheus`验证，成功情况下应该出现如下内容：
```text
# HELP system_cpu_count The number of processors available to the Java virtual machine
# TYPE system_cpu_count gauge
system_cpu_count 4.0
# HELP process_uptime_seconds The uptime of the Java virtual machine
# TYPE process_uptime_seconds gauge
process_uptime_seconds 347.673
# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next
# TYPE jvm_gc_memory_allocated_bytes_total counter
jvm_gc_memory_allocated_bytes_total 7.6690036E8
# HELP process_files_open_files The open file descriptor count
# TYPE process_files_open_files gauge
process_files_open_files 123.0
# HELP tomcat_global_error_total  
# TYPE tomcat_global_error_total counter
tomcat_global_error_total{name="http-nio-8080",} 6.0
...
```

## Prometheus配置增加业务服务的job

Prometheus无法和部署在PCF上的Eureka集成，因而选择在一台可以访问公网的HOST上部署prometheus-server。并对每个按照上述部署的微服务增加对应的抓取指标的JOB配置。

```YAML
scrape_configs:
  - job_name: 'actuator-client'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 15s
    static_configs:
    - targets: ['<HOSTNAME>']

# ...
```
重启prometheus-server后可以在prometheus提供的简易web界面上调试，验证自己的微服务的指标数据是否能够成功抓取。

## 配置业务服务的Grafana监控大盘

TBD

# RabbitMQ监控
## 准备RabbitMQ Admin账号

生产环境的RabbitMQ使用PCF提供的服务实例，需要先在PCF上创建可以使用RabbitMQ Admin HTTP API的账号。

```
cf create-service-key My-RabbitMQ-Service rabbitmq_exporter
```

使用如下命令获取RabbitMQ各个节点的元数据
```
cf service-key My-RabbitMQ-Service rabbitmq_exporter
```
数据如下形式：
```json
{
 "dashboard_url": "https://rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/#/login/HOSTNAME/PASSWORD",
 "hostname": "10.227.200.200",
 "hostnames": [
  "10.227.200.200"
 ],
 "http_api_uri": "https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/",
 "http_api_uris": [
  "https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com/api/"
 ],
 "password": "PASSWORD",
 "protocols": {
  "amqp": {
   "host": "10.227.200.200",
   "hosts": [
    "10.227.200.200"
   ],
   "password": "PASSWORD",
   "port": 5672,
   "ssl": false,
   "uri": "amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a",
   "uris": [
    "amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a"
   ],
   "username": "HOSTNAME",
   "vhost": "d9a9c1ab-2383-400b-b5e8-3b84dabe221a"
  }
 },
 "ssl": false,
 "uri": "amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a",
 "uris": [
  "amqp://HOSTNAME:PASSWORD@10.227.200.200/d9a9c1ab-2383-400b-b5e8-3b84dabe221a"
 ],
 "username": "HOSTNAME",
 "vhost": "d9a9c1ab-2383-400b-b5e8-3b84dabe221a"
}
```

## 部署rabbitmq_exporter应用

在Host `192.168.8.101`上对每一个RabbitMQ节点部署一个rabbitmq_exporter应用，提供prometheus访问的metrics endpoint

```
 RABBIT_URL=https://HOSTNAME:PASSWORD@rmq-d9a9c1ab-2383-400b-b5e8-3b84dabe221a.sys.example.cf.company.com RABBIT_USER=HOSTNAME RABBIT_PASSWORD=PASSWORD PUBLISH_PORT=9419 ./rabbitmq_exporter
```
如果RabbitMQ节点会动态变化，则需要一个可以动态对每个节点启动一个RabbitMQ Exporter实例的策略。TBD

在Prometheus Server的配置中增加rabbitmq_exporter的抓取配置。
```
scrape_configs:
  - job_name: 'rabbitmq_exporter'
    metrics_path: '/metrics'
    scrape_interval: 15s
    static_configs:
    - targets: ['192.168.8.101:9419']
```
对于RabbitMQ Exporter动态多节点的情况，需要进一步制定配置动态生成策略。TBD

## 配置RabbitMQ的Grafana监控大盘

{% asset_img grafana-dashboard-rabbitmq.png %}

# Redis监控

## 开发redis_exporter
生产环境的Redis时PCF提供的服务实例，目前没有可以直接调用的API。为了获取Redis资源的运行状况，需要开发一个部署在PCF上的redis_exporter应用。redis_exporter应用类似rabbitmq_exporter，充当Prometheus和Redis之间的桥接器。

redis_exporter API定义参见 [使用Client Java构建Exporter程序](https://yunlzheng.gitbook.io/prometheus-book/part-ii-prometheus-jin-jie/exporter/custom_exporter_with_java/client_library_java)。TBD


## Prometheus配置增加抓取redis_exporter的job

TBD

## 配置Redis的Grafana监控大盘

{% asset_img grafana-dashboard-redis.png %}


# DB监控

[Azure Dashboard](https://portal.azure.cn/#@chinaford.partner.onmschina.cn/dashboard/private/7ea953d4-0837-4c2e-a1e7-d0a685c4c00f)


# 告警及处理
## 业务异常告警
项目生产环境使用Splunk处理log数据。团队使用Webex Teams作为沟通工具。功能篇里描述的业务异常告警采用如下方式实现。
- 定义Splunk搜索异常的查询语句
- 定义Splunk Alert，选择webhook作为trigger action
- 实现Splunk Webhook的Target Endpoint接收Splunk Alert Message（TBD）
- Splunk Webhook Target Endoint发送Message到Webex Teams群组

### 配置Splunk Alert

在splunk里定义我们关心的Exception查询语句，并保存为Alert Rule。  

Alert配置里设置Trigger Action，使用Webex Teams Webhook。

### 实现Splunk Alert Webex Bridge
因为Splunk不支持外网webhook，所以只能使用Splunk发送消息到webex teams，再由webex teams发送消息给bridge的方法。  
实现一个Bridge应用，定义接收来自splunk alert的Target Endpoint（TODO）。Target Endpoint接口定义如下：
URL: `POST /bridge/splunk`
Request Body: 
```json
{

	"result": {
		"sourcetype" : "mongod",
		"count" : "8"
	},
	"sid" : "scheduler_admin_search_W2_at_14232356_132",
	"results_link" : "http://web.example.local:8000/app/search/@go?sid=scheduler_admin_search_W2_at_14232356_132",
	"search_name" : null,
	"owner" : "admin",
	"app" : "search"
}
```
Target Endpoint接到Splunk Alert后，需要将Alert按照定义好的Webex Teams消息的格式，调用Webex Teams的Create Message API，发送消息到特定Channel。


### 配置Splunk Alert Throttle策略

Splunk提供了Alert Throttle功能，使用此功能实现Alert发送成功后静默一段时间的策略。


## Metrics告警
系统的监控部分构建了Metrics监控能力，对于Metrics的Alert实现方法如下：

- 使用Grafana管理Metrics Alert Rule
- 使用Grafana Webhook Notification Channel完成通知环节
- 实现Grafana Alert Bridge应用，接收Webhook通知
- Grafana Alert Bridge负责转发alert通知到Webex Teams

## 告警处理
当告警出现，开发跟进alert的流程需要结合Webex Teams进行。实现方案选择如下：

- 配置Webex Teams Webhook功能
- 实现Webex Teams Webhook Target Endpoint接收消息
- Webex Teams Webhook Target Endpoint跟进Alert的类型，选择处理流程
- 当Alert是来自Splunk的Exception Alert时，记录处理人信息
- 当Alert是来自Grafana的Metrics Alelrt时，记录处理人信息，调用Grafana Alert API，暂停对应Alert一段时间
- 当接到处理结束信息，跟进Alert类型选择处理流程
- 当Alert是来自Splunk的Exception Alert时，记录处理结果信息
- 当Alert是来自Grafana的Metrics Alelrt时，记录处理结果信息，调用Grafana Alert API，恢复对应Alert一段时间

### Webex Teams Webhook配置

TODO

### Target Endpoint接口定义

URL： `POST /bridge/webex/alert`  
Request Body:
```json
{
  "id": "Y2lzY29zcGFyazovL3VzL1dFQkhPT0svZjRlNjA1NjAtNjYwMi00ZmIwLWEyNWEtOTQ5ODgxNjA5NDk3",
  "name": "New message in 'Project Unicorn' room",
  "resource": "messages",
  "event": "created",
  "filter": "roomId=Y2lzY29zcGFyazovL3VzL1JPT00vYmJjZWIxYWQtNDNmMS0zYjU4LTkxNDctZjE0YmIwYzRkMTU0",
  "orgId": "OTZhYmMyYWEtM2RjYy0xMWU1LWExNTItZmUzNDgxOWNkYzlh",
  "createdBy": "Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY",
  "appId": "Y2lzY29zcGFyazovL3VzL0FQUExJQ0FUSU9OL0MyNzljYjMwYzAyOTE4MGJiNGJkYWViYjA2MWI3OTY1Y2RhMzliNjAyOTdjODUwM2YyNjZhYmY2NmM5OTllYzFm",
  "ownedBy": "creator",
  "status": "active",
  "actorId": "Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY",
  "data":{
    "id": "Y2lzY29zcGFyazovL3VzL01FU1NBR0UvOTJkYjNiZTAtNDNiZC0xMWU2LThhZTktZGQ1YjNkZmM1NjVk",
    "roomId": "Y2lzY29zcGFyazovL3VzL1JPT00vYmJjZWIxYWQtNDNmMS0zYjU4LTkxNDctZjE0YmIwYzRkMTU0",
    "personId": "Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNWIzNjE4Ny1jOGRkLTQ3MjctOGIyZi1mOWM0NDdmMjkwNDY",
    "personEmail": "matt@example.com",
    "created": "2015-10-18T14:26:16.000Z"
  }
}
```
Target Endpoint 需要分析携带的消息内容，跟进消息内容解析出对应的指令，然后执行对应操作。
目前需要支持的指令有：
- `process #<Alert Id>`
- `finished #<Alert Id>`
- `validated #<Alert Id>`
- `release #<Alert Id>`





















